{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from keras import backend as K \n",
    "from keras.preprocessing import image\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model, Model\n",
    "from keras.layers import GlobalAveragePooling2D, Dense\n",
    "#from keras.layers import GlobalAveragePooling2D, Dropout, Dense\n",
    "from keras.applications import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_name(k):\n",
    "    return 'model_'+str(k)+'.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/media/7D63-84F2/data/ISIC2018_Task3_Training_GroundTruth_new.csv')\n",
    "\n",
    "Y = train_data[['label']]\n",
    "\n",
    "kf = KFold(n_splits = 5)\n",
    "\n",
    "VALIDATION_ACCURACY = []\n",
    "VALIDATION_LOSS = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = '/media/7D63-84F2/data/ISIC2018_Task3_Training_Input/'\n",
    "save_dir = './saved_models/'\n",
    "fold_var = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "idg = image.ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                        rotation_range=40,\n",
    "                        width_shift_range=0.2,\n",
    "                        height_shift_range=0.2,\n",
    "                        zoom_range=0.2,\n",
    "                        shear_range=0.2,\n",
    "                        fill_mode='nearest',\n",
    "                        horizontal_flip = True,\n",
    "                        rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8012 validated image filenames belonging to 7 classes.\n",
      "Found 2003 validated image filenames belonging to 7 classes.\n",
      "Epoch 1/5\n",
      "1002/1002 [==============================] - 389s 388ms/step - loss: 1.2745 - accuracy: 0.6271 - val_loss: 3.7283 - val_accuracy: 0.6860\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.68597, saving model to ./saved_models/model_1.h5\n",
      "Epoch 2/5\n",
      "1002/1002 [==============================] - 336s 336ms/step - loss: 1.2335 - accuracy: 0.6278 - val_loss: 9.6664 - val_accuracy: 0.6860\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.68597\n",
      "Epoch 3/5\n",
      "1002/1002 [==============================] - 330s 330ms/step - loss: 1.2542 - accuracy: 0.6226 - val_loss: 0.0462 - val_accuracy: 0.6860\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.68597\n",
      "Epoch 4/5\n",
      "1002/1002 [==============================] - 330s 330ms/step - loss: 1.2517 - accuracy: 0.6264 - val_loss: 3.4021 - val_accuracy: 0.6860\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.68597\n",
      "Epoch 5/5\n",
      "1002/1002 [==============================] - 330s 329ms/step - loss: 1.2703 - accuracy: 0.6224 - val_loss: 10.0417 - val_accuracy: 0.6860\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.68597\n",
      "251/251 [==============================] - 51s 203ms/step\n",
      "Found 8012 validated image filenames belonging to 7 classes.\n",
      "Found 2003 validated image filenames belonging to 7 classes.\n",
      "Epoch 1/5\n",
      "1002/1002 [==============================] - 360s 360ms/step - loss: 1.2767 - accuracy: 0.6271 - val_loss: 3.1717 - val_accuracy: 0.6875\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.68747, saving model to ./saved_models/model_2.h5\n",
      "Epoch 2/5\n",
      "1002/1002 [==============================] - 333s 333ms/step - loss: 1.2449 - accuracy: 0.6308 - val_loss: 1.1245e-04 - val_accuracy: 0.6875\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.68747\n",
      "Epoch 3/5\n",
      "1002/1002 [==============================] - 332s 331ms/step - loss: 1.2430 - accuracy: 0.6218 - val_loss: 2.3647 - val_accuracy: 0.6875\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.68747\n",
      "Epoch 4/5\n",
      "1002/1002 [==============================] - 333s 332ms/step - loss: 1.2468 - accuracy: 0.6269 - val_loss: 4.7007 - val_accuracy: 0.6875\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.68747\n",
      "Epoch 5/5\n",
      "1002/1002 [==============================] - 330s 329ms/step - loss: 1.2795 - accuracy: 0.6219 - val_loss: 0.0061 - val_accuracy: 0.6875\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.68747\n",
      "251/251 [==============================] - 56s 222ms/step\n",
      "Found 8012 validated image filenames belonging to 7 classes.\n",
      "Found 2003 validated image filenames belonging to 7 classes.\n",
      "Epoch 1/5\n",
      "1002/1002 [==============================] - 351s 350ms/step - loss: 1.2741 - accuracy: 0.6263 - val_loss: 0.0054 - val_accuracy: 0.6850\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.68497, saving model to ./saved_models/model_3.h5\n",
      "Epoch 2/5\n",
      "1002/1002 [==============================] - 337s 336ms/step - loss: 1.2391 - accuracy: 0.6222 - val_loss: 12.8526 - val_accuracy: 0.6850\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.68497\n",
      "Epoch 3/5\n",
      "1002/1002 [==============================] - 333s 333ms/step - loss: 1.2334 - accuracy: 0.6252 - val_loss: 5.4405 - val_accuracy: 0.6850\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.68497\n",
      "Epoch 4/5\n",
      "1002/1002 [==============================] - 332s 331ms/step - loss: 1.2583 - accuracy: 0.6218 - val_loss: 7.3134 - val_accuracy: 0.6850\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.68497\n",
      "Epoch 5/5\n",
      "1002/1002 [==============================] - 335s 335ms/step - loss: 1.2766 - accuracy: 0.6184 - val_loss: 3.2216 - val_accuracy: 0.6850\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.68497\n",
      "251/251 [==============================] - 63s 253ms/step\n",
      "Found 8012 validated image filenames belonging to 7 classes.\n",
      "Found 2003 validated image filenames belonging to 7 classes.\n",
      "Epoch 1/5\n",
      "1002/1002 [==============================] - 351s 351ms/step - loss: 1.2710 - accuracy: 0.6253 - val_loss: 2.6720 - val_accuracy: 0.6970\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.69695, saving model to ./saved_models/model_4.h5\n",
      "Epoch 2/5\n",
      "1002/1002 [==============================] - 331s 330ms/step - loss: 1.2596 - accuracy: 0.6269 - val_loss: 2.5616 - val_accuracy: 0.6970\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.69695\n",
      "Epoch 3/5\n",
      "1002/1002 [==============================] - 332s 331ms/step - loss: 1.2632 - accuracy: 0.6231 - val_loss: 2.5978 - val_accuracy: 0.6970\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.69695\n",
      "Epoch 4/5\n",
      "1002/1002 [==============================] - 331s 330ms/step - loss: 1.2791 - accuracy: 0.6133 - val_loss: 1.5313 - val_accuracy: 0.6970\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.69695\n",
      "Epoch 5/5\n",
      "1002/1002 [==============================] - 331s 330ms/step - loss: 1.2717 - accuracy: 0.6151 - val_loss: 9.1872 - val_accuracy: 0.6970\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.69695\n",
      "251/251 [==============================] - 70s 280ms/step\n",
      "Found 8012 validated image filenames belonging to 7 classes.\n",
      "Found 2003 validated image filenames belonging to 7 classes.\n",
      "Epoch 1/5\n",
      "1002/1002 [==============================] - 350s 349ms/step - loss: 1.2423 - accuracy: 0.6419 - val_loss: 6.5972 - val_accuracy: 0.5921\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.59211, saving model to ./saved_models/model_5.h5\n",
      "Epoch 2/5\n",
      "1002/1002 [==============================] - 331s 331ms/step - loss: 1.2078 - accuracy: 0.6519 - val_loss: 3.9315 - val_accuracy: 0.5921\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.59211\n",
      "Epoch 3/5\n",
      "1002/1002 [==============================] - 332s 331ms/step - loss: 1.2127 - accuracy: 0.6497 - val_loss: 6.3175 - val_accuracy: 0.5921\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.59211\n",
      "Epoch 4/5\n",
      "1002/1002 [==============================] - 332s 331ms/step - loss: 1.2110 - accuracy: 0.6470 - val_loss: 3.3027 - val_accuracy: 0.5921\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.59211\n",
      "Epoch 5/5\n",
      "1002/1002 [==============================] - 331s 331ms/step - loss: 1.2290 - accuracy: 0.6424 - val_loss: 0.6311 - val_accuracy: 0.5716\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.59211\n",
      "251/251 [==============================] - 79s 314ms/step\n"
     ]
    }
   ],
   "source": [
    "for train_index, val_index in kf.split(np.zeros(10015),Y):\n",
    "    training_data = train_data.iloc[train_index]\n",
    "    validation_data = train_data.iloc[val_index]\n",
    "\n",
    "    train_data_generator = idg.flow_from_dataframe(training_data,\n",
    "                                                   directory = image_dir,\n",
    "                                                   x_col = \"filename\",\n",
    "                                                   y_col = \"label\",\n",
    "                                                   target_size=(75, 75),\n",
    "                                                   batch_size=8,\n",
    "                                                   color_mode=\"rgb\",\n",
    "                                                   class_mode = \"categorical\",\n",
    "                                                   shuffle = True)\n",
    "    \n",
    "    valid_data_generator  = idg.flow_from_dataframe(validation_data,\n",
    "                                                    directory = image_dir,\n",
    "                                                    x_col = \"filename\",\n",
    "                                                    y_col = \"label\",\n",
    "                                                    target_size=(75, 75),\n",
    "                                                    batch_size=8,\n",
    "                                                    color_mode=\"rgb\",\n",
    "                                                    class_mode = \"categorical\",\n",
    "                                                    shuffle = True)\n",
    "\n",
    "    # CREATE NEW MODEL\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "    CLASSES = 7\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    # x = Dropout(0.4)(x)\n",
    "    predictions = Dense(CLASSES, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # COMPILE NEW MODEL\n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # CREATE CALLBACKS\n",
    "    checkpoint = ModelCheckpoint(save_dir+get_model_name(fold_var), \n",
    "                            monitor='val_accuracy', verbose=1, \n",
    "                            save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    # There can be other callbacks, but just showing one because it involves the model name\n",
    "    # This saves the best model\n",
    "    # FIT THE MODEL\n",
    "    \n",
    "    EPOCHS = 5\n",
    "    #STEPS_PER_EPOCH = 126\n",
    "    #steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    history = model.fit_generator(\n",
    "        train_data_generator,\n",
    "        epochs=EPOCHS,\n",
    "        verbose=1,\n",
    "        callbacks=callbacks_list,\n",
    "        validation_data=valid_data_generator)\n",
    " \n",
    "    #PLOT HISTORY\n",
    "    #\t\t:\n",
    "    #\t\t:\n",
    "\n",
    "    # LOAD BEST MODEL to evaluate the performance of the model\n",
    "    model.load_weights(\"./saved_models/model_\"+str(fold_var)+\".h5\")\n",
    "\n",
    "    results = model.evaluate(valid_data_generator)\n",
    "    results = dict(zip(model.metrics_names,results))\n",
    "\n",
    "    VALIDATION_ACCURACY.append(results['accuracy'])\n",
    "    VALIDATION_LOSS.append(results['loss'])\n",
    "\n",
    "    K.clear_session()\n",
    "    \n",
    "    fold_var += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6859710216522217,\n",
       " 0.6874687671661377,\n",
       " 0.6849725246429443,\n",
       " 0.6969545483589172,\n",
       " 0.5921118259429932]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VALIDATION_ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.954578876495361,\n",
       " 2.9831764698028564,\n",
       " 0.006127266678959131,\n",
       " 3.0566112995147705,\n",
       " 6.360202312469482]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VALIDATION_LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('resultsfile.txt', 'w') as f:\n",
    "    f.write('Validation Accuracy\\n')\n",
    "    f.writelines(\"%s, \" % num for num in VALIDATION_ACCURACY)\n",
    "    f.write('\\nValidation Loss\\n')\n",
    "    f.writelines(\"%s, \" % num for num in VALIDATION_LOSS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
